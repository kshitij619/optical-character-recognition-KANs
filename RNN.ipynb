{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451c615e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m X_seq \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m))\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Split data\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X_seq, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShapes:\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_train\u001b[38;5;241m.\u001b[39mshape, y_train\u001b[38;5;241m.\u001b[39mshape, X_test\u001b[38;5;241m.\u001b[39mshape, y_test\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# =========================\u001b[39;00m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Define RNN model\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# =========================\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yashm\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\yashm\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2805\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2801\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[0;32m   2803\u001b[0m train, test \u001b[38;5;241m=\u001b[39m ensure_common_namespace_device(arrays[\u001b[38;5;241m0\u001b[39m], train, test)\n\u001b[1;32m-> 2805\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2806\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[0;32m   2807\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m   2808\u001b[0m     )\n\u001b[0;32m   2809\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\yashm\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2807\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2801\u001b[0m     train, test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X\u001b[38;5;241m=\u001b[39marrays[\u001b[38;5;241m0\u001b[39m], y\u001b[38;5;241m=\u001b[39mstratify))\n\u001b[0;32m   2803\u001b[0m train, test \u001b[38;5;241m=\u001b[39m ensure_common_namespace_device(arrays[\u001b[38;5;241m0\u001b[39m], train, test)\n\u001b[0;32m   2805\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2806\u001b[0m     chain\u001b[38;5;241m.\u001b[39mfrom_iterable(\n\u001b[1;32m-> 2807\u001b[0m         (_safe_indexing(a, train), _safe_indexing(a, test)) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrays\n\u001b[0;32m   2808\u001b[0m     )\n\u001b[0;32m   2809\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\yashm\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_indexing.py:176\u001b[0m, in \u001b[0;36m_safe_indexing\u001b[1;34m(X, indices, axis)\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err_msg)\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err_msg)\n\u001b[1;32m--> 176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_safe_indexing\u001b[39m(X, indices, \u001b[38;5;241m*\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    177\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return rows, items or columns of X using indices.\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \n\u001b[0;32m    179\u001b[0m \u001b[38;5;124;03m    .. warning::\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;124;03m    array([1, 3, 5])\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    227\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# RNN OCR (Aâ€“Z Dataset) â€” Keras / TensorFlow\n",
    "# =========================\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, models, callbacks, optimizers\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# --- Load or prepare your dataset ---\n",
    "# Example:\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"A_Z Handwritten Data.csv\").astype('float32')\n",
    "X = data.drop('0', axis=1).values.reshape(-1,28,28,1) / 255.0\n",
    "y_labels = data['0'].values\n",
    "y = tf.keras.utils.to_categorical(y_labels, num_classes=26)\n",
    "\n",
    "# Ensure arrays exist and are correct dtype\n",
    "X = X.astype('float32')\n",
    "y = y.astype('float32')\n",
    "\n",
    "# Convert to (samples, timesteps, features)\n",
    "X_seq = X.reshape((-1, 28, 28))\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_seq, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "print(\"Shapes:\", X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "\n",
    "# =========================\n",
    "# Define RNN model\n",
    "# =========================\n",
    "def build_rnn_model(time_steps=28, features=28, num_classes=26, rnn_units=128, dropout=0.3):\n",
    "    inp = layers.Input(shape=(time_steps, features))\n",
    "    x = layers.Bidirectional(layers.LSTM(rnn_units, return_sequences=True))(inp)\n",
    "    x = layers.Bidirectional(layers.LSTM(rnn_units // 2))(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.Dense(128, activation='relu')(x)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    out = layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = models.Model(inputs=inp, outputs=out, name=\"BiLSTM_OCR\")\n",
    "    return model\n",
    "\n",
    "rnn_model = build_rnn_model()\n",
    "rnn_model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=1e-3),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "rnn_model.summary()\n",
    "\n",
    "# =========================\n",
    "# Training setup\n",
    "# =========================\n",
    "EPOCHS = 10\n",
    "BATCH = 128\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "MODEL_PATH = \"models/rnn_ocr_model.keras\"\n",
    "\n",
    "cb = [\n",
    "    callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1),\n",
    "    callbacks.ModelCheckpoint(MODEL_PATH, monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "]\n",
    "\n",
    "print(\"\\nðŸš€ Training started...\")\n",
    "history = rnn_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH,\n",
    "    callbacks=cb,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Evaluate\n",
    "# =========================\n",
    "loss, acc = rnn_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"\\nâœ… Test accuracy: {acc*100:.2f}% â€” Loss: {loss:.4f}\")\n",
    "\n",
    "# =========================\n",
    "# Save a downloadable .h5 model file\n",
    "# =========================\n",
    "H5_PATH = \"models/rnn_ocr_model.h5\"\n",
    "rnn_model.save(H5_PATH)\n",
    "print(f\"ðŸ“¦ Model saved for frontend: {H5_PATH}\")\n",
    "\n",
    "# =========================\n",
    "# Plot training curves\n",
    "# =========================\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='val')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='val')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# =========================\n",
    "# Prediction helper\n",
    "# =========================\n",
    "import cv2\n",
    "def predict_from_image_rnn(image_path, model=rnn_model):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        raise FileNotFoundError(image_path)\n",
    "    img = cv2.resize(img, (28,28))\n",
    "    img = img.astype('float32') / 255.0\n",
    "    seq = img.reshape(1,28,28)\n",
    "    pred = model.predict(seq)\n",
    "    label = np.argmax(pred, axis=1)[0]\n",
    "    print(\"Predicted:\", chr(label + 65))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"Predicted: {chr(label+65)}\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
